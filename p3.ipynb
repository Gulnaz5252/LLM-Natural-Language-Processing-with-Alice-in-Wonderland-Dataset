{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "mzWlNgAIoSdQ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afoP3WYroSdS",
    "outputId": "f94ce91d-9e6c-4919-ffe0-4d906d606fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversatio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Download the Gutenberg corpus (only needed once)\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "raw = gutenberg.raw('carroll-alice.txt')\n",
    "print(raw[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj-7iL9IoSdS"
   },
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJsuTWkSoSdT",
    "outputId": "aa9c57ec-333c-4c93-8210-d043d976c2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1640 sentences in this book\n"
     ]
    }
   ],
   "source": [
    "# Write a function to count sentences\n",
    "def count_sentences(text):\n",
    "    sent_count = 0\n",
    "\n",
    "    for char in text:\n",
    "        if char in '.!?':  # Handle multiple sentence-ending punctuation marks\n",
    "            sent_count += 1\n",
    "\n",
    "    return sent_count\n",
    "\n",
    "sent_count = count_sentences(raw)\n",
    "print(f'There are {sent_count} sentences in this book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_cSR2wmoSdU",
    "outputId": "d3c78dae-b63f-4bc8-90d0-0946cb646a4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'s\", 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit-Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize sentences\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "token_words = word_tokenize(raw)\n",
    "print(token_words[:40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82d8mzanoSdU",
    "outputId": "e4e8c6b5-64c2-40bd-bf04-ab3405bef03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 12\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "## Type solution here ##\n",
    "# I decided to keep new lines\n",
    "# Define a function to split text into chapters based on some pattern\n",
    "\n",
    "def split_into_chapters(text):\n",
    "    # Example pattern for chapters (may need adjustment based on actual text format)\n",
    "    chapter_pattern = re.compile(r'\\nCHAPTER +')\n",
    "    chapters = re.split(chapter_pattern, text)\n",
    "\n",
    "    # Remove empty chapters if any\n",
    "    chapters = [chapter.strip() for chapter in chapters if chapter.strip()]\n",
    "\n",
    "    return chapters\n",
    "\n",
    "chapters = split_into_chapters(raw)\n",
    "\n",
    "# Store chapters in a dictionary with chapter number or title as key\n",
    "chapter_dict = {i+1: chapter for i, chapter in enumerate(chapters)}\n",
    "\n",
    "# Print the number of chapters\n",
    "print(f\"Number of chapters: {len(chapter_dict)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibo2tbHuoSdW",
    "outputId": "de104a79-49ed-4032-fd43-2c4296beaa5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version= 4.42.4\n"
     ]
    }
   ],
   "source": [
    "## Provided this Cell  ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "MODEL_PATH= '/Users/yerdenovagulnaz/Downloads/EP_models/'\n",
    "os.environ['HF_HOME'] = MODEL_PATH  # before import transformers\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# filter warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "print(f'transformers version= {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ITXKBKGmoSdX"
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer_qa = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "model_qa = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model_qa, tokenizer=tokenizer_qa, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyWFdEBGoSdX"
   },
   "source": [
    "## LLM- Masked  - Question-Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhQgvZWP3Lr_",
    "outputId": "eb952601-4c17-47f2-f618-f6eca20917f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer_m = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_m = BertForMaskedLM.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUNfkWAbkxOX",
    "outputId": "28ecc880-afc7-4236-95a0-c52fce7fc0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probable word after 'Alice in' is: wonderland\n"
     ]
    }
   ],
   "source": [
    "text = \"Alice in [MASK].\"\n",
    "input_ids = tokenizer_m.encode(text, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input_ids == tokenizer_m.mask_token_id)[1]\n",
    "\n",
    "# Predict the masked word\n",
    "with torch.no_grad():\n",
    "    output = model_m(input_ids)\n",
    "    predictions = output.logits[0, mask_token_index, :]\n",
    "\n",
    "# Extract the predicted token ID for the masked token\n",
    "predicted_index = torch.argmax(predictions).item()\n",
    "predicted_token = tokenizer_m.decode([predicted_index])\n",
    "\n",
    "print(f\"The most probable word after 'Alice in' is: {predicted_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXOjLB3vp3Vx"
   },
   "source": [
    " I am using masked language model (MLM) approach which seems to be the most reasonable for this task. The approach is to mask the word that needs to be predicted, then use the model to find it.\n",
    "\n",
    "The answer is correct, even without fine tunning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxXon31goSdX"
   },
   "source": [
    "## Large Language Model - Question-Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "QKQ2F14tkglE"
   },
   "outputs": [],
   "source": [
    "# Write a function to split the corpus into chunks that will be suitable for LLM\n",
    "def split_into_chunks(text, chunk_size, overlap_size):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap_size):\n",
    "        chunks.append(' '.join(words[i: i + chunk_size]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UZ5K88Yp228",
    "outputId": "f6e54638-cd0c-4afa-9107-764f15db6a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Rabbit's catchphrase?\n",
      "A: UNimportant\n",
      "\n",
      "Q: What makes Alice shrink?\n",
      "A: the fan she was holding\n",
      "\n",
      "Q: What is the Queen's full name?\n",
      "A: The Queen of Hearts\n",
      "\n",
      "Q: What game does Alice play?\n",
      "A: croquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForQuestionAnswering, pipeline\n",
    "\n",
    "# Parameters\n",
    "chunk_size = 500\n",
    "overlap_size = 20\n",
    "\n",
    "# Split the text into chunks with overlap\n",
    "chunks = split_into_chunks(raw, chunk_size, overlap_size)\n",
    "\n",
    "# Function to find the best answer from all the chunks\n",
    "def get_best_answer(question, chunks):\n",
    "    answers = []\n",
    "    scores = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = qa_pipeline(question=question, context=chunk)\n",
    "        answers.append(result['answer'])\n",
    "        scores.append(result['score'])\n",
    "\n",
    "    # Rank answers by score\n",
    "    if scores:\n",
    "        best_index = scores.index(max(scores))\n",
    "        return answers[best_index]\n",
    "\n",
    "    return \"No answer found\"\n",
    "\n",
    "# List of questions\n",
    "questions = [\n",
    "    \"What is Rabbit's catchphrase?\",\n",
    "    \"What makes Alice shrink?\",\n",
    "    \"What is the Queen's full name?\",\n",
    "    \"What game does Alice play?\"\n",
    "]\n",
    "\n",
    "# Get answers for each question\n",
    "answers = {q: get_best_answer(q, chunks) for q in questions}\n",
    "\n",
    "# Print the answers\n",
    "for question, answer in answers.items():\n",
    "    print(f\"Q: {question}\\nA: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIcrjdC5k_V1",
    "outputId": "83201a67-4677-467c-dfa4-cbea12fe6458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Rabbit's catchphrase?\n",
      "A: 'Silence in the court!'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a pattern to match the White Rabbit's dialogue\n",
    "pattern = re.compile(\n",
    "    r'\\bRabbit\\b.*?(?:said|cried|exclaimed|asked|muttered|remarked|called|replied|added|begged|whispered)\\b.*?(?:\"[^\"]*\"|\\'[^\\']*\\')',\n",
    "    re.IGNORECASE | re.DOTALL\n",
    ")\n",
    "\n",
    "# Find all matches in the raw text\n",
    "matches = pattern.findall(raw)\n",
    "\n",
    "# Join all matches into a single string with each dialogue on a new line\n",
    "dialogues = \"\\n\".join(matches)\n",
    "\n",
    "# Split the text into chunks with overlap\n",
    "chunks_r = split_into_chunks(dialogues, chunk_size, overlap_size)\n",
    "\n",
    "answer = get_best_answer(\"What is Rabbit's saying?\", chunks_r)\n",
    "print(f\"Q: What is Rabbit's catchphrase?\\nA: {answer}\\n\")\n",
    "\n",
    "# The answer is not correct, we did not improved it using more specific dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1I_iKCTi8zs",
    "outputId": "848bc7c8-4d72-45b8-e741-41031b634412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What makes Alice shrink??\n",
      "A: the fan she was holding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find all sentences containing word shrink from raw to improve the answer to What causes Alice to shrink? question\n",
    "\n",
    "sentences = sent_tokenize(raw)\n",
    "shrink_sentences = [sentence for sentence in sentences if 'shrink' in sentence.lower()]\n",
    "\n",
    "answer = get_best_answer(\"What causes Alice to shrink?\", shrink_sentences)\n",
    "print(f\"Q: What makes Alice shrink??\\nA: {answer}\\n\")\n",
    "# The answer did not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "gXbD3q9GoSdY"
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "qa_pipeline_2 = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vIDR6b5kv1F",
    "outputId": "ccc4b78e-46e8-4a98-e4c3-4a199e095865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Rabbit's catchphrase?\n",
      "A: 'Your Majesty must cross-examine THIS witness\n",
      "\n",
      "Q: What makes Alice shrink?\n",
      "A: sneezing\n",
      "\n",
      "Q: What is the Queen's full name?\n",
      "A: Alice\n",
      "\n",
      "Q: What game does Alice play?\n",
      "A: croquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForQuestionAnswering, pipeline\n",
    "\n",
    "# Parameters\n",
    "chunk_size = 500\n",
    "overlap_size = 20\n",
    "\n",
    "# Split the text into chunks with overlap\n",
    "chunks = split_into_chunks(raw, chunk_size, overlap_size)\n",
    "\n",
    "# Function to find the best answer from all the chunks\n",
    "def get_best_answer(question, chunks):\n",
    "    answers = []\n",
    "    scores = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = qa_pipeline_2(question=question, context=chunk)\n",
    "        answers.append(result['answer'])\n",
    "        scores.append(result['score'])\n",
    "\n",
    "    # Rank answers by score\n",
    "    if scores:\n",
    "        best_index = scores.index(max(scores))\n",
    "        return answers[best_index]\n",
    "\n",
    "    return \"No answer found\"\n",
    "\n",
    "# List of questions\n",
    "questions = [\n",
    "    \"What is Rabbit's catchphrase?\",\n",
    "    \"What makes Alice shrink?\",\n",
    "    \"What is the Queen's full name?\",\n",
    "    \"What game does Alice play?\"\n",
    "]\n",
    "\n",
    "# Get answers for each question\n",
    "answers = {q: get_best_answer(q, chunks) for q in questions}\n",
    "\n",
    "# Print the answers\n",
    "for question, answer in answers.items():\n",
    "    print(f\"Q: {question}\\nA: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCzJcWtpoSdY"
   },
   "source": [
    "## LLM - Question-Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V68EyyUyoSdY",
    "outputId": "06e8f608-882d-4a9b-8f0c-70e0a35b3273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who wrote Alice's Adventures in Wonderland?\n",
      "A: Lewis Carroll\n",
      "\n",
      "Q: Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\n",
      "A: Johnny Depp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Type solution here ##\n",
    "answer = qa_pipeline(\"Who wrote Alice's Adventures in Wonderland?\", chapters[0])\n",
    "print(f\"Q: Who wrote Alice's Adventures in Wonderland?\\nA: {answer['answer']}\\n\")\n",
    "\n",
    "# A chunk of an article from wikipedia\n",
    "context = \"Johnny Depp as Tarrant Hightopp / Mad Hatter:[8] Wasikowska said that the characters 'both feel like outsiders and feel alone in their separate worlds, and have a special bond and friendship.'[9][10] Burton explained that Depp 'tried to find a grounding to the character … as opposed to just being mad.'[11] Burton also said that '[i]n a lot of versions it's a very one-note kind of character and you know [Depp's] goal was to try and bring out a human side to the strangeness of the character.'[11] The orange hair is an allusion to the mercury poisoning suffered by hatters who used mercury to cure felt; Depp believes that the character 'was poisoned … and it was coming out through his hair, through his fingernails and eyes'.[12] Depp and Burton decided that the Hatter's clothes, skin, hair, personality and accent would change throughout the film to reflect his emotions.[13] In an interview with Depp, the character was paralleled to 'a mood ring, [as] his emotions are very close to the surface'.[14] The Hatter is 'made up of different people and their extreme sides', with a gentle voice much like the character's creator Lewis Carroll reflecting the lighter personality and with a Scottish Glaswegian accent (which Depp modeled after Gregor Fisher's Rab C. Nesbitt character) reflecting a darker, more dangerous personality.[15] Illusionary dancer David 'Elsewhere' Bernal doubled for Depp during the 'Futterwacken' sequence near the end of the film.[16]\"\n",
    "answer_1 = qa_pipeline(\"Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\", context)\n",
    "print(f\"Q: Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\\nA: {answer_1['answer']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wftDnjOEoSdZ"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "frzc8K9IoSdZ"
   },
   "outputs": [],
   "source": [
    "## Type solution here ##\n",
    "\n",
    "# Function to split text into chunks of a given size with whole sentences\n",
    "def split_into_chunks_2(text, max_length=512, tokenizer=None):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize and check if adding this sentence exceeds the max length\n",
    "        tokenized_chunk = tokenizer.encode(chunk + \" \" + sentence, truncation=False)\n",
    "        if len(tokenized_chunk) > max_length:\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "            chunk = sentence\n",
    "        else:\n",
    "            chunk += \" \" + sentence\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X87J_Z00nwFD",
    "outputId": "1e87a6ec-8f22-4a15-a795-21d55f318116"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 1: Sentiment: neutral, Score: 0.8965\n",
      "Chapter 1 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.6451\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.8079\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.6030\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.5376\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.5231\n",
      "  Chunk 6: Sentiment: negative, Score: 0.5252\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.7869\n",
      "Chapter 2 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.5201\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.7270\n",
      "  Chunk 3: Sentiment: negative, Score: 0.5061\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.7401\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.6866\n",
      "  Chunk 6: Sentiment: negative, Score: 0.5637\n",
      "Chapter 3 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.8181\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.8285\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.7266\n",
      "  Chunk 4: Sentiment: negative, Score: 0.4905\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.6108\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.5551\n",
      "Chapter 4 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.7524\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.7750\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.5436\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.6908\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.5509\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.7729\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.5480\n",
      "  Chunk 8: Sentiment: neutral, Score: 0.8382\n",
      "Chapter 5 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.7705\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.6176\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.7521\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.7762\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.6566\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.7229\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.6289\n",
      "Chapter 6 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.8304\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.6649\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.5969\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.6950\n",
      "  Chunk 5: Sentiment: negative, Score: 0.5826\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.5645\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.7527\n",
      "  Chunk 8: Sentiment: neutral, Score: 0.7693\n",
      "Chapter 7 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.7965\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.7579\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.6590\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.7722\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.7397\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.7232\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.7138\n",
      "Chapter 8 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.8331\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.8071\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.5837\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.7070\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.5506\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.6514\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.7339\n",
      "Chapter 9 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: positive, Score: 0.8119\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.7256\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.7062\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.6610\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.6777\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.5413\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.5344\n",
      "Chapter 10 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.6182\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.5846\n",
      "  Chunk 3: Sentiment: positive, Score: 0.8725\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.8226\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.7982\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.7861\n",
      "  Chunk 7: Sentiment: positive, Score: 0.7986\n",
      "Chapter 11 overall sentiment: neutral\n",
      "\n",
      "  Chunk 1: Sentiment: neutral, Score: 0.7677\n",
      "  Chunk 2: Sentiment: neutral, Score: 0.7377\n",
      "  Chunk 3: Sentiment: neutral, Score: 0.9108\n",
      "  Chunk 4: Sentiment: neutral, Score: 0.5309\n",
      "  Chunk 5: Sentiment: neutral, Score: 0.7291\n",
      "  Chunk 6: Sentiment: neutral, Score: 0.4989\n",
      "  Chunk 7: Sentiment: neutral, Score: 0.7710\n",
      "  Chunk 8: Sentiment: neutral, Score: 0.7956\n",
      "  Chunk 9: Sentiment: neutral, Score: 0.7875\n",
      "  Chunk 10: Sentiment: neutral, Score: 0.7487\n",
      "  Chunk 11: Sentiment: neutral, Score: 0.6001\n",
      "  Chunk 12: Sentiment: neutral, Score: 0.6475\n",
      "Chapter 12 overall sentiment: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Load the sentiment analysis model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", device=0)\n",
    "\n",
    "# Predict sentiment for each chapter and print all sentiments with hard voting\n",
    "for chapter_number, chapter_text in chapter_dict.items():\n",
    "    # Split the chapter into smaller chunks\n",
    "    chunks = split_into_chunks_2(chapter_text, max_length=512, tokenizer=sentiment_pipeline.tokenizer)\n",
    "\n",
    "    # Collect sentiments for each chunk\n",
    "    chunk_sentiments = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        result = sentiment_pipeline(chunk)\n",
    "        sentiment_label = result[0]['label']\n",
    "        chunk_sentiments.append(sentiment_label)\n",
    "        print(f\"  Chunk {i+1}: Sentiment: {sentiment_label}, Score: {result[0]['score']:.4f}\")\n",
    "\n",
    "    # Perform hard voting to determine the overall chapter sentiment\n",
    "    sentiment_counter = Counter(chunk_sentiments)\n",
    "    most_common_sentiment, _ = sentiment_counter.most_common(1)[0]\n",
    "\n",
    "    print(f\"Chapter {chapter_number} overall sentiment: {most_common_sentiment}\")\n",
    "    print()  # Print a newline for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW9xG5U4oSdZ"
   },
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "r7c5nXd8oSda"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Create a summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, max_length=100, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXBHXoWLqEkE",
    "outputId": "61584136-2ea2-46e9-ccbc-2475ceca2d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Alice fell down a rabbit-hole after a White Rabbit with pink eyes. She had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it. 'I wonder how many miles I've fallen by this time?' she said aloud. 'How funny it'll seem among the people that I walk with their heads downward!'\n",
      "\n",
      "Chunk 2:\n",
      "Alice was walking hand in hand with Dinah, and saying to her very earnestly, 'Now, Dinah,. tell me the truth: did you ever eat a bat?' When suddenly, thump! thumps! down she came upon a heap of sticks and dry leaves, and the fall was over. Alice was not a bit hurt, and she jumped up on to her feet in a moment. But it was all dark overhead; before her was another long passage, and\n",
      "\n",
      "Chunk 3:\n",
      "Alice was very fond of pretending to be two people. She generally gave herself very good advice, (though she very seldom followed it) and sometimes scolded herself so severely as to bring tears into her eyes. She once tried to box her own ears for having                cheated herself in a game of croquet she was playing against herself.\n",
      "\n",
      "Chunk 4:\n",
      "'Curiouser and curiouser!' cried Alice (she was so much surprised, that for the moment she quite forgot how to speak good English) 'Now I'm opening out like the largest telescope that ever was! Good-bye, feet!' 'Oh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears?' 'I'll give them a new pair of boots every Christmas'\n",
      "\n",
      "Chunk 5:\n",
      "Alice was a little girl who had never been so small before. She was playing in a pool of water when she began to shrink. She thought she had fallen into the sea, but then realized she was in the pool of which she had once been nine feet high. 'I must have been changed,' she thought, 'and I must be growing small again'\n",
      "\n",
      "Chunk 6:\n",
      "Alice spoke to a mouse for the first time in her life. The Mouse looked at her ratherinquisitively, and seemed to wink with one of its little eyes, but it said nothing. 'Perhaps it doesn't understand English,' thought Alice; 'I daresay it's a French mouse, come over with William the Conqueror'\n",
      "\n",
      "Chunk 7:\n",
      "A Caucus-Race and a Long Tale. A queer-looking party that assembled on the bank. The first question of course was, how to get dry again. The Mouse said, 'Sit down, all of you, and listen to me! I'LL soon make you dry enough!'\n",
      "\n",
      "Chunk 8:\n",
      "The story of the Dodo and the Mouse begins with a race between two birds. The Dodo wins the race, and all the birds are given prizes. But who is to give the prizes to Alice? 'Why, SHE, of course,' says the Mouse, pointing to Alice with one finger.\n",
      "\n",
      "Chunk 9:\n",
      "'I wish I had our Dinah here, I know I do!' said Alice aloud, addressing nobody in particular. 'And who is Dinah, if I might venture to ask the question?' said the Lory. Alice replied eagerly, for she was always ready to talk about her pet: 'Dinah's our cat. And she's such a capital one for catching mice you can't think!'\n",
      "\n",
      "Chunk 10:\n",
      "Alice was sent on a journey by the Rabbit to find a pair of gloves and a fan. She found a neat little house, on the door of which was a bright brassplate with the name 'W. RABBIT' engraved upon it. She went in without knocking, and hurried upstairs, in great fear lest she should meet the real Mary Ann, and be turned out of the house before she had found the fan and gloves. There she found a bottle with the words '\n",
      "\n",
      "Chunk 11:\n",
      "Alice heard the Rabbit just under the window, and made a snatch in the air. She did not get hold of anything, but she heard a little shriek and a fall, and a crash of broken glass. The Rabbit came up to the door, and tried to open it, but the door opened inwards, and Alice's elbow was pressed hard against it.\n",
      "\n",
      "Chunk 12:\n",
      "Alice heard a chorus of voices, then the Rabbit's voice, 'Catch him, you by the hedge!' 'We must burn the house down!' said the Rabbit. 'If you do. I'll set Dinah at you!' said Alice. A shower of little pebbles came rattling in at the window, and some of them hit her in the face. 'I'll put a stop to this,' she said to herself, and shouted out, 'You'd\n",
      "\n",
      "Chunk 13:\n",
      "Alice was playing with a puppy, when a large caterpillar appeared. The Caterpillar asked her, 'Who are YOU?' Alice replied, 'I hardly know, sir, just at present--at least I know who I WAS when I got up this morning, but I think I must have beenchanged several times since then' 'Explain yourself!' said the Caterpillar sternly. 'I can't explain MYSELF, I'm afraid, sir' said Alice, '\n",
      "\n",
      "Chunk 14:\n",
      "'I've tried to say \"HOW DOTH THE LITTLE BUSY BEE,\" but it all came differently,' said the Caterpillar. Alice thought she might as well wait, as she had nothing else to do, and perhaps after all it might tell her something worth hearing. 'What size do you want to be?' it asked.\n",
      "\n",
      "Chunk 15:\n",
      "'You'll get used to it in time,' said the Caterpillar. 'I haven't the least idea what you're talking about,' said Alice. 'As it wasn't trouble enough hatching the eggs, I must look-out for serpents! Why, I haven't had a wink of sleep these three weeks!'\n",
      "\n",
      "Chunk 16:\n",
      "'I'm NOT a serpent, I tell you!' said Alice. 'I've seen a good many little girls in my time, but never ONE with such a neck as that!' 'Well, be off, then!' said the Pigeon in a sulky tone. Alice crouched down among the trees as well as she could, for her neck kept getting entangled among the branches.\n",
      "\n",
      "Chunk 17:\n",
      "Alice went timidly up to the door, and knocked. 'There's no sort of use in knocking,' said the Footman. 'They're making such a noise inside, no one could possibly hear you' 'How am I to get in?' asked Alice again, in a louder tone. 'That's the first question, you know' 'I shall sit here,' he said, 'on and off, for days and days'\n",
      "\n",
      "Chunk 18:\n",
      "'If everybody minded their own business,' the Duchess said in a hoarse growl, 'the world would go round a deal faster than it does' 'Which would NOT be an advantage,' said Alice, who felt very glad to get an opportunity of showing off a little of her knowledge. 'Here! you may nurse it a bit, if you like!' said the Duchess.\n",
      "\n",
      "Chunk 19:\n",
      "Alice was carrying the pig home when she saw the Cheshire Cat. 'If you're going to turn into a pig, my dear,' said Alice, seriously, 'I'll have nothing more to do with you' 'Call it what you like,' said the Cat, 'Do you play croquet with the Queen to-day?' 'I should like it very much,' saidAlice, 'but I haven't been invited yet'\n",
      "\n",
      "Chunk 20:\n",
      "Alice went to visit the March Hare, who was having a tea-party. The March Hare and the Hatter were having tea at a table with a Dormouse. The Hatter asked Alice, 'Why is a raven like a writing-desk?' 'At least I mean what I say--that's the same thing, you know,' said Alice.\n",
      "\n",
      "Chunk 21:\n",
      "The Hatter and the March Hare were drinking tea. The Hatter had taken his watch out of hispocket, and was looking at it uneasily, shaking it every now and then, and holding it to his ear. Alice had been looking over his shoulder with some curiosity. 'What a funny watch!' she remarked. 'It tells the day of the month, and doesn't tell what o'clock it is!' 'Why should it?' muttered the Hatter.\n",
      "\n",
      "Chunk 22:\n",
      "The Hatter and the March Hare asked Alice to tell them a story. 'Once upon a time there were three little sisters,' said the Dormouse, 'and their names were Elsie, Lacie, and Tillie; and they lived at the bottom of a well--' 'What did they live on?' said Alice, who always took a great interest in eating and drinking. 'They lived on treacle' said theDormouse. 'But why did they\n",
      "\n",
      "Chunk 23:\n",
      "'I don't understand,' said Alice, 'where did they draw the treacle from?' 'They were IN the well,' said the Dormouse, 'well in' 'Why with an M?' said Alice. 'Why not?' said the March Hare. Alice was silent. She got up in disgust, and walked off. The Dormouses fell asleep instantly.\n",
      "\n",
      "Chunk 24:\n",
      "Three gardeners were lying on their faces in the garden, waiting for the Queen to come. The Queen shouted at them 'Get up!' and the three jumped up. 'You shan't beheaded!' said the Queen, 'You make me giddy!' The Queen turned crimson with fury, and screamed 'Off with her head!'\n",
      "\n",
      "Chunk 25:\n",
      "'It's--it's a very fine day!' said a timid voice at her side. 'Can you play croquet?' shouted Alice. 'Their heads are gone, if it please your Majesty!' the soldiers shouted back. 'Come on, then!' roared the Queen, and Alice joined the procession.\n",
      "\n",
      "Chunk 26:\n",
      "'I don't think they play at all fairly,' Alice began, in rather acomplaining tone. 'They all quarrel so dreadfully one can't hear                oneself speak' 'I should have croqueted the Queen's hedgehog just now, only                it ran away when it saw mine coming!' 'How do you like the Queen?' said the Cat in a low voice. 'Not at all,' said Alice: 'she's so extremely--'\n",
      "\n",
      "Chunk 27:\n",
      "The Cat's head began fading away the moment he was gone, and, by the time he had come back with the Duchess, it had entirely disappeared. Alice was very glad to find her in such a pleasant temper, and thought perhaps it was only the pepper that had made her so savage when they met in the kitchen.\n",
      "\n",
      "Chunk 28:\n",
      "Alice was playing croquet with the Duchess and the Queen. The Queen was shouting at the other players, and shouting 'Off with his head!' 'I don't even know what a Mock Turtle is,' said Alice. 'That's nothing to what I could say if I chose,' said the Duchess. 'Pray don't trouble yourself to say it any longer than that,' saidAlice.\n",
      "\n",
      "Chunk 29:\n",
      "Alice and the Gryphon went up to the Mock Turtle, who looked at them with large eyes full of tears, but said nothing. 'Sit down, both of you, and don't speak a word till I've finished,' he said. So they sat down, and nobody spoke for some minutes. The Mock Turtle at last, with a deep sigh, said: 'I was a real Turtle.' These words were followed by a very long silence.\n",
      "\n",
      "Chunk 30:\n",
      "'I can't show it you myself,' the Mock Turtle said: 'I'm too                stiff. And the Gryphon never learnt it.' 'I went to the Classics master, though. He was an old crab, HE was' 'What a curious plan!' exclaimed Alice. 'That's the reason they're called lessons' 'Because they lessen from day to day' 'And how did you manage on the twelfth?' Alice went on eagerly.\n",
      "\n",
      "Chunk 31:\n",
      "Alice heard a curious song about the whiting. 'Do you know why it's called a whiting?' said the Gryphon. 'IT DOES THE BOOTS AND SHOES' said the Mock Turtle. 'Boots and shoes under the sea?' said Alice. 'They're done with blacking, I believe'\n",
      "\n",
      "Chunk 32:\n",
      "'I could tell you my adventures--beginning from this morning,' said Alice a little timidly. 'No, no! The adventures first,' said the Gryphon in an impatient tone: 'explanations take such a dreadful time' So Alice began telling them her adventures from the time when she first saw the White Rabbit. Her listeners were perfectly quiet till she got to the part about her repeating 'YOU ARE OLD, FATHER WILLIAM,' to the Cater\n",
      "\n",
      "Chunk 33:\n",
      "The King and Queen of Hearts were seated on their throne with a great crowd assembled about them. Alice had never been in a court of justice before, but she had read about them in books. She was quite pleased to find that she knew the name of nearly everything there. The twelve jurors were all writing very busily on slates.\n",
      "\n",
      "Chunk 34:\n",
      "The Hatter, the March Hare and the Dormouse appeared before the King. The King accused the Hatter of having stolen tarts from the Queen of Hearts. Alice, who was growing larger, stood up and took a pencil from one of the jurors. 'Don't be nervous, or I'll have you executed on the spot,' said the King angrily.\n",
      "\n",
      "Chunk 35:\n",
      "'I'm a poor man, your Majesty,' he began. 'You're a very poor speaker,' said the King. Here one of the guinea-pigs cheered, and was immediately suppressed by the officers of the court. The next witness was the Duchess's cook. 'What are tarts made of mostly?' said the cook.\n",
      "\n",
      "Chunk 36:\n",
      "Alice's evidence was read out by the White Rabbit. The jury were asked to write a history of the accident. They were just beginning to write this when the King said: 'The trial cannot proceed until all the jurymen are back in their proper places' The King cackled out 'Silence!' and read out from his book. 'Forty-two. ALL PERSONS more than a MILE HIGH to LEAVE THE COURT'\n",
      "\n",
      "Chunk 37:\n",
      "'There'snothing written on the OUTSIDE,' said the White Rabbit. 'It isn't a letter, after all: it's a set of verses' 'Are they in the prisoner's handwriting?' asked another of the jurymen. 'No, they're not,' said White Rabbit, 'and that's the queerest thingabout it' 'He must have imitated somebody else's hand,' said King. 'That PROVES his guilt,' said Queen. 'Why\n",
      "\n",
      "Chunk 38:\n",
      "'Let the jury consider their verdict,' said the King. 'No, no!' said the Queen. 'Sentence first--verdict afterwards.' 'Stuff and nonsense!' said Alice loudly. 'The idea of having the purposefullysentence first!' 'Hold your tongue!' says the Queen, turning purple. 'I won't!' says Alice. 'Off with her head!' the Queen shouted at the top of her voice.\n",
      "\n",
      "Chunk 39:\n",
      "She pictured to herself how this same little sister of hers would, in the after-time, be herself a grown woman. She would gather about her other little children, and make their eyes bright and eager with many a strange tale, perhaps even with the dream of Wonderland of long ago. How she would feel their simple sorrows, and find a pleasure in all their simple joys, remembering her own child-life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the long text into chunks\n",
    "chunks = split_into_chunks_2(raw, max_length=1024, tokenizer=tokenizer)\n",
    "\n",
    "# Predict for each chunk\n",
    "results = [summarizer(chunk) for chunk in chunks]\n",
    "\n",
    "# Print the results for each chunk\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(result[0]['summary_text'])  # Adjust based on the pipeline task\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
